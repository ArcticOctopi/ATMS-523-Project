{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923d45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import math\n",
    "from pyproj import CRS, Transformer\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import xesmf as xe\n",
    "import matplotlib.pyplot as plt\n",
    "import fsspec \n",
    "from dask.distributed import Client, progress\n",
    "import re\n",
    "from cfgrib import xarray_to_grib\n",
    "import pickle\n",
    "import gc\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f76233",
   "metadata": {},
   "source": [
    "Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf6bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable that determines the minimum storm strength. Anything\n",
    "# below the variable will be retained.\n",
    "CMP_MAX = 1000.0\n",
    "\n",
    "# AWS S3 bucket where the HAFS data is stored.\n",
    "BUCKET_NAME = 'noaa-nws-hafs-pds'\n",
    "\n",
    "# Variables that will not be loaded. Remaining variables are ['gh', 't', 'r', 'u', 'v']\n",
    "DROP_VARIABLES = ['q', 'w', 'wz', 'absv', 'clwmr', 'icmr', 'rwmr', 'snmr','grle', 'rare', 'dpt']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the dask and s3 client\n",
    "\n",
    "try:\n",
    "    from dask.distributed import get_client\n",
    "    get_client().close()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "client = Client()  # set up local cluster on your laptop\n",
    "client\n",
    "\n",
    "fs = fsspec.filesystem('s3', anon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23576a7",
   "metadata": {},
   "source": [
    "Project Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_processing(s3_path: str):\n",
    "    '''\n",
    "    Docstring for frame_processing\n",
    "    \n",
    "   Args:\n",
    "        s3_path (string): The path to the location in the NOAA HAFS S3 bucket \n",
    "                          for a given model run timestep.\n",
    "        \n",
    "\n",
    "    Checks for frame validity:\n",
    "        Central minimum pressure less than cutoff global variable (CMP_Max)\n",
    "    \n",
    "    If valid returns a Model Dataset consisting of:\n",
    "        PBL temp, heights, rh, and u/v winds\n",
    "        700 mb temp, heights, rh, and u/v winds\n",
    "        central minimum pressure for the frame,\n",
    "        maximum wind for the frame.\n",
    "\n",
    "    Will convert the entire dataset to a polar grid\n",
    "    and rotate so storm heading is the reference azimuth.\n",
    "    '''\n",
    "    # Setting up the function cache\n",
    "    header_path = 'simplecache::s3://noaa-nws-hafs-pds/'\n",
    "\n",
    "    # Complete path for 24 hr timestep\n",
    "    frame_path = header_path + s3_path\n",
    "\n",
    "    # Complete path for 27 hr timestep\n",
    "    nxt_frame_path = header_path = re.sub('.f024', '.f027', frame_path)\n",
    "\n",
    "    # Opens 24 hour timestep. Will be stored in cache.\n",
    "    frame_file = fsspec.open_local(frame_path, s3={'anon': True}, filecache={'cache_storage':'/tmp/files'})\n",
    "    \n",
    "\n",
    "    # Opening the 24hr sfc data into a dataset\n",
    "    ds_sfc = xr.open_dataset(frame_file,  \n",
    "                         filter_by_keys={'typeOfLevel': 'meanSea'},\n",
    "                         engine = 'cfgrib')\n",
    "    \n",
    "    # Checking to see if the storm meets strength thresholds.\n",
    "    # If it doesn't, function will return none.\n",
    "    ds_sfc = ds_sfc['prmsl'].compute()/100 #prmsl from pascals to mb\n",
    "    c_mslp = ds_sfc.min()\n",
    "    if c_mslp > CMP_MAX:\n",
    "        print(f\"{c_mslp.values} does not meet the threshold\")\n",
    "        return None, None\n",
    "    else:\n",
    "        center_coords = ds_sfc.where(ds_sfc == c_mslp, drop=True).squeeze()\n",
    "\n",
    "    # Opening 27 hr timestep. Will be stored in cache.\n",
    "    nxt_frame_file = fsspec.open_local(nxt_frame_path, s3={'anon': True}, filecache={'cache_storage':'/tmp/files'})\n",
    "\n",
    "    # Opening atmospheric data into a dataset\n",
    "    ds_atm = xr.open_dataset(frame_file,\n",
    "                         drop_variables = DROP_VARIABLES, \n",
    "                         filter_by_keys={'typeOfLevel': 'isobaricInhPa'},\n",
    "                         engine = 'cfgrib'\n",
    "                        )   \n",
    "    \n",
    "    # Opening 27 hr sfc data into a dataset. Required for determining storm direction.\n",
    "    ds_sfc_nxt_step = xr.open_dataset(nxt_frame_file, \n",
    "                         filter_by_keys={'typeOfLevel': 'meanSea'},\n",
    "                         engine = 'cfgrib')\n",
    "    \n",
    "    # Filtering atmospheric data to only include 700mb level and surface.\n",
    "    # Surface is determined by selecting the level in the original data\n",
    "    # nearest to the minimum central pressure.\n",
    "    ds_atm = ds_atm.sel(isobaricInhPa = [c_mslp.values, 700.0], method = 'nearest')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Computing Storm center at the 27 hr timestep. Necessary for determining\n",
    "    # storm motion.\n",
    "    ds_sfc_nxt_step = ds_sfc_nxt_step['prmsl'].compute()\n",
    "    c_mslp_nxt_step = ds_sfc_nxt_step.min()\n",
    "    center_coords_nxt_step = ds_sfc_nxt_step.where(ds_sfc_nxt_step == c_mslp_nxt_step, drop=True).squeeze()\n",
    "\n",
    "    # Calculating storm heading.\n",
    "    storm_heading = calc_heading(center_coords.latitude.values, center_coords.longitude.values, \n",
    "                                 center_coords_nxt_step.latitude.values, center_coords_nxt_step.longitude.values)\n",
    "    \n",
    "    # Computing maximum wind at the sfc.\n",
    "    max_wind = np.nanmax(np.sqrt(ds_atm['u'].isel(isobaricInhPa = 0).values**2 + ds_atm['v'].isel(isobaricInhPa = 0).values**2))\n",
    "    \n",
    "    # regridding dataset to polar coordinates and rotating to place storm heading \n",
    "    # as the reference heading.\n",
    "    frame = to_polar(ds_atm.compute(),\n",
    "                     origin_lat= center_coords.latitude.values,\n",
    "                     origin_lon= center_coords.longitude.values,\n",
    "                     storm_heading = storm_heading)\n",
    "    \n",
    "    # Storing the 700mb (atm_object) and sfc (sfc_object) data into two dictionaries\n",
    "    atm_object = {\n",
    "                    'radius_coords': frame.radius.values,\n",
    "                    'angle_coords': frame.angle.values,\n",
    "                    'gh': frame['gh'].isel(isobaricInhPa = 0).values,\n",
    "                    't': frame['t'].isel(isobaricInhPa = 0).values,\n",
    "                    'r': frame['r'].isel(isobaricInhPa = 0).values,\n",
    "                    'u': frame['u'].isel(isobaricInhPa = 0).values,\n",
    "                    'v': frame['v'].isel(isobaricInhPa = 0).values,\n",
    "                    'center_lat': center_coords.latitude.values,\n",
    "                    'center_lon': center_coords.longitude.values,\n",
    "                    'valid_time': frame.isel(isobaricInhPa = 0).valid_time.values,\n",
    "                    'storm_heading': storm_heading\n",
    "                    }\n",
    "    sfc_object = {\n",
    "                    'radius_coords': frame.radius.values,\n",
    "                    'angle_coords': frame.angle.values,\n",
    "                    'gh': frame['gh'].isel(isobaricInhPa = 1).values,\n",
    "                    't': frame['t'].isel(isobaricInhPa = 1).values,\n",
    "                    'r': frame['r'].isel(isobaricInhPa = 1).values,\n",
    "                    'u': frame['u'].isel(isobaricInhPa = 1).values,\n",
    "                    'v': frame['v'].isel(isobaricInhPa = 1).values,\n",
    "                    'center_pressure': c_mslp.values,\n",
    "                    'max_wind': max_wind,\n",
    "                    'center_lat': center_coords.latitude.values,\n",
    "                    'center_lon': center_coords.longitude.values,\n",
    "                    'valid_time': frame.valid_time.values,\n",
    "                    'storm_heading': storm_heading\n",
    "                    }\n",
    "                    \n",
    "    \n",
    "    return sfc_object, atm_object\n",
    "    \n",
    "def calc_heading(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "    '''\n",
    "        Calculates storm heading\n",
    "\n",
    "        Args:\n",
    "            lat1/lon1: latitude/longitude coordinates of the initial timestep\n",
    "            lat2/lon2: latitude/longitude coordinates of the follow-on timestep\n",
    "        \n",
    "        Returns:\n",
    "            bearing: A storm motion heading in degrees\n",
    "    '''\n",
    "    lat1_rad = np.deg2rad(lat1)\n",
    "    lat2_rad = np.deg2rad(lat2)\n",
    "    lon1_rad = np.deg2rad(lon1)\n",
    "    lon2_rad = np.deg2rad(lon2)\n",
    "\n",
    "    d_lon = lon2_rad - lon1_rad\n",
    "\n",
    "    y = np.sin(d_lon) * np.cos(lat2_rad)\n",
    "    x = (np.cos(lat1_rad) * np.sin(lat2_rad) -\n",
    "         np.sin(lat1_rad) * np.cos(lat2_rad) * np.cos(d_lon)) \n",
    "    \n",
    "    initial_bearing_rad = np.arctan2(y, x)\n",
    "\n",
    "    initial_bearing_deg = np.rad2deg(initial_bearing_rad)\n",
    "\n",
    "    bearing = (initial_bearing_deg + 360) % 360\n",
    "\n",
    "    return bearing \n",
    "\n",
    "def rotate_point_around_origin(x, y, angle: float):\n",
    "    \"\"\"\n",
    "    Rotates a 2D point (x, y) or 2D meshgrid of points around the origin (0, 0) by a given angle.\n",
    "\n",
    "    Args:\n",
    "        x (float): The x-coordinate of the point or a 2D meshgrid of x-coordinates.\n",
    "        y (float): The y-coordinate of the point or a 2D meshgrid of y-coordinates.\n",
    "        angle_degrees (float): The angle of rotation in radians (counter-clockwise).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple (new_x, new_y) or two meshgrids representing the rotated point or reference system.\n",
    "    \"\"\"\n",
    "    # Converts the angle to radians and transforms it for clockwise rotation\n",
    "    angle = -(np.deg2rad(angle))\n",
    "\n",
    "    new_x = x * math.cos(angle) - y * math.sin(angle)\n",
    "    new_y = x * math.sin(angle) + y * math.cos(angle)\n",
    "    return new_x, new_y\n",
    "\n",
    "def to_polar(\n",
    "        ds: xr.Dataset,\n",
    "        origin_lat: float,\n",
    "        origin_lon: float,\n",
    "        storm_heading: float,\n",
    "        R_max = 250.0, # Max range in km\n",
    "        R_step = 0.5, # Range step in km\n",
    "        A_step = 0.5  # Azimuth step in degrees\n",
    "    ) -> xr.Dataset:\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        R = 6378137 # radius of Earth in meters\n",
    "\n",
    "        new_range = np.arange(0.0, R_max + R_step, R_step)\n",
    "        new_azimuth = np.arange(0.0, 360.0, A_step)\n",
    "        R, T = np.meshgrid(new_azimuth, new_range, indexing = 'ij')\n",
    "     \n",
    "        X = R * np.cos(T) * 1000 # Convert km to meters\n",
    "        Y = R * np.sin(T) * 1000 # Convert km to meters\n",
    "        local_proj_str = f\"+proj=aeqd +lat_0={origin_lat} +lon_0={origin_lon} +units=m\"\n",
    "        transformer = pyproj.Transformer.from_crs(local_proj_str, \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "        X,Y = rotate_point_around_origin(X, Y, storm_heading)\n",
    "        target_lons, target_lats = transformer.transform(X, Y)\n",
    "        \n",
    "        ds_out = xr.Dataset(\n",
    "                            coords={\n",
    "                                    \"latitude\": ((\"angle\", \"radius\"), target_lats),\n",
    "                                    \"longitude\": ((\"angle\", \"radius\"), target_lons),\n",
    "                                    \"radius\": new_range,\n",
    "                                    \"angle\": new_azimuth\n",
    "                                        }\n",
    "                            )\n",
    "        regridder = xe.Regridder(ds, ds_out, 'bilinear')\n",
    "        polar_out = regridder(ds)\n",
    "       \n",
    "        return polar_out\n",
    "\n",
    "\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_list = []\n",
    "\n",
    "with open('Data/links/link_list.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                loaded_list.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_frame = 0\n",
    "list_length = 1000\n",
    "save_rate = 2\n",
    "partial_loaded_list = loaded_list[starting_frame:(starting_frame+list_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddafbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_700mb = {\n",
    "                    'radius_coords': [],\n",
    "                    'angle_coords': [],\n",
    "                    'gh': [],\n",
    "                    't': [],\n",
    "                    'r': [],\n",
    "                    'u': [],\n",
    "                    'v': [],\n",
    "                    'valid_time': [],\n",
    "                    'center_lat': [],\n",
    "                    'center_lon': [],\n",
    "                    'storm_heading': []\n",
    "    }\n",
    "\n",
    "frames_sfc = {\n",
    "                    'radius_coords': [],\n",
    "                    'angle_coords': [],\n",
    "                    'gh': [],\n",
    "                    't': [],\n",
    "                    'r': [],\n",
    "                    'u': [],\n",
    "                    'v': [],\n",
    "                    'center_pressure': [],\n",
    "                    'max_wind': [],\n",
    "                    'valid_time': [],\n",
    "                    'center_lat': [],\n",
    "                    'center_lon': [],\n",
    "                    'storm_heading': []\n",
    "\n",
    "    }\n",
    "\n",
    "for i, frame_path in enumerate(partial_loaded_list):\n",
    "    \n",
    "    print(i)\n",
    "    try:\n",
    "        sfc_frame, atm_frame = frame_processing(frame_path)\n",
    "        frame = True\n",
    "        if not sfc_frame:\n",
    "            frame = False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Issue with link {frame_path}\")\n",
    "        print(e)\n",
    "        frame = False\n",
    "        \n",
    "    if frame:\n",
    "        \n",
    "        frames_700mb['radius_coords'].append(atm_frame['radius_coords'])\n",
    "        frames_700mb['angle_coords'].append(atm_frame['angle_coords'])\n",
    "        frames_700mb['gh'].append(atm_frame['gh'])\n",
    "        frames_700mb['t'].append(atm_frame['t'])\n",
    "        frames_700mb['r'].append(atm_frame['r'])\n",
    "        frames_700mb['u'].append(atm_frame['u'])\n",
    "        frames_700mb['v'].append(atm_frame['v'])\n",
    "        frames_700mb['valid_time'].append(atm_frame['valid_time'])\n",
    "       \n",
    "\n",
    "        frames_sfc['radius_coords'].append(sfc_frame['radius_coords'])\n",
    "        frames_sfc['angle_coords'].append(sfc_frame['angle_coords'])\n",
    "        frames_sfc['gh'].append(sfc_frame['gh'])\n",
    "        frames_sfc['t'].append(sfc_frame['t'])\n",
    "        frames_sfc['r'].append(sfc_frame['r'])\n",
    "        frames_sfc['u'].append(sfc_frame['u'])\n",
    "        frames_sfc['v'].append(sfc_frame['v'])\n",
    "        frames_sfc['center_pressure'].append(sfc_frame['center_pressure'])\n",
    "        frames_sfc['max_wind'].append(sfc_frame['max_wind'])\n",
    "        frames_sfc['valid_time'].append(sfc_frame['valid_time'])\n",
    "        frames_sfc['center_lat'].append(sfc_frame['center_lat'])\n",
    "        frames_sfc['center_lon'].append(sfc_frame['center_lon'])\n",
    "        frames_sfc['storm_heading'].append(sfc_frame['storm_heading'])\n",
    "\n",
    "    # Checking to see if the current frame meets a datasave checkpoint\n",
    "    # If yes, will create a netcdf of up to save_rate samples (will vary\n",
    "    # based on how many samples meet the strength threshold.)   \n",
    "    if i%save_rate == 0:\n",
    "        \n",
    "        # For naming the saved netcdf\n",
    "        ending_frame = i\n",
    "       \n",
    "        ds = xr.Dataset(\n",
    "                        data_vars = {\n",
    "                                    'gh': (['levels','valid_time', 'angle', 'radius' ], \n",
    "                                        np.stack([frames_sfc['gh'], frames_700mb['gh']]),\n",
    "                                        {'units': 'm', 'long_name': 'Geopotential Height'}),\n",
    "                                    'rh': (['levels','valid_time','angle', 'radius'], \n",
    "                                        np.stack([frames_sfc['r'], frames_700mb['r']]),\n",
    "                                        {'units': 'percent humidity', 'long_name': 'Relative Humidity'}),\n",
    "                                    't': (['levels','valid_time', 'angle', 'radius'], \n",
    "                                        np.stack([frames_sfc['t'], frames_700mb['t']]),\n",
    "                                        {'units': 'K', 'long_name': 'Air Temperature'}),\n",
    "                                    'u': (['levels','valid_time', 'angle', 'radius'], \n",
    "                                        np.stack([frames_sfc['u'], frames_700mb['u']]),\n",
    "                                        {'units': 'm/s', 'long_name': 'U wind'}),\n",
    "                                    'v': (['levels','valid_time', 'angle', 'radius'], \n",
    "                                        np.stack([frames_sfc['v'], frames_700mb['v']]),\n",
    "                                        {'units': 'm/s', 'long_name': 'V wind'}),\n",
    "                                    'center_pressure': (['valid_time'], \n",
    "                                                        frames_sfc['center_pressure'],\n",
    "                                                        {'units': 'mb', 'long_name': 'Central Minimum Pressure in the Storm Environment'}),\n",
    "                                    'max_wind': (['valid_time'], \n",
    "                                                frames_sfc['max_wind'],\n",
    "                                                {'units': 'm/s', 'long_name': 'Maximum Wind Speed in the Storm Environment'}),\n",
    "                                    'center_lat': (['valid_time'], \n",
    "                                                frames_sfc['center_lat'],\n",
    "                                                {'units': 'degrees latitude', 'long_name': 'Latitude of Storm Center'}),\n",
    "                                    'center_lon': (['valid_time'], \n",
    "                                                frames_sfc['center_lon'],\n",
    "                                                {'units': 'degrees longitude', 'long_name': 'Longitude of Storm Center'}),\n",
    "                                    'storm_heading': (['valid_time'], \n",
    "                                                frames_sfc['storm_heading'],\n",
    "                                                {'units': 'degrees', 'long_name': 'Storm Heading relative to Lat/Lon Center'}),\n",
    "                                },\n",
    "                            coords= {\n",
    "                                    'angle': ('angle',\n",
    "                                            frames_sfc['angle_coords'][0],\n",
    "                                            {'units': 'degreees', 'long_name': 'Azimuth around Storm Center'}), \n",
    "                                    'radius': ('radius',\n",
    "                                            frames_sfc['radius_coords'][0],\n",
    "                                            {'units': 'km', 'long_name': 'Range from Storm Center'}), \n",
    "                                    'valid_time': frames_sfc['valid_time'],\n",
    "                                    'levels': (['sfc', 700])\n",
    "                                    },\n",
    "                            attrs= {'history': f'Created on {date.today()}',\n",
    "                                    'Overview': ('Data originally obtained from the HAFS Repository ' \n",
    "                                                    '(https://registry.opendata.aws/noaa-nws-hafs/) '\n",
    "                                                    'hosted on the AWS Sustainability Data Initiative. '\n",
    "                                                    'Data was regridded and interpolated from the original '\n",
    "                                                    'Lat/Lon grid to a regular polar grid centered on storm '\n",
    "                                                    'center. The center was determined by finding the lowest '\n",
    "                                                    'surface pressure within the surface pressure field. '\n",
    "                                                    'Storm heading was determined by finding the center location '\n",
    "                                                    'in the following time step and calculating the heading between '\n",
    "                                                    'those two points. Sfc field level data is determined by finding the '\n",
    "                                                    'pressure level in the dataset nearest the central minimum pressure.')}        \n",
    "                )\n",
    "        ds.to_netcdf(f'CompleteData/StormData{starting_frame}To{ending_frame}.nc')\n",
    "\n",
    "        # Resetting the two data dictionaries\n",
    "        frames_700mb = {\n",
    "                    'radius_coords': [],\n",
    "                    'angle_coords': [],\n",
    "                    'gh': [],\n",
    "                    't': [],\n",
    "                    'r': [],\n",
    "                    'u': [],\n",
    "                    'v': [],\n",
    "                    'valid_time': [],\n",
    "                    'center_lat': [],\n",
    "                    'center_lon': [],\n",
    "                    'storm_heading': []\n",
    "                        }\n",
    "\n",
    "        frames_sfc = {\n",
    "                    'radius_coords': [],\n",
    "                    'angle_coords': [],\n",
    "                    'gh': [],\n",
    "                    't': [],\n",
    "                    'r': [],\n",
    "                    'u': [],\n",
    "                    'v': [],\n",
    "                    'center_pressure': [],\n",
    "                    'max_wind': [],\n",
    "                    'valid_time': [],\n",
    "                    'center_lat': [],\n",
    "                    'center_lon': [],\n",
    "                    'storm_heading': []\n",
    "\n",
    "                     }\n",
    "        # For naming the next netcdf file\n",
    "        starting_frame = ending_frame + 1\n",
    "        \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATMS523-Proj-Everything-Else",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
